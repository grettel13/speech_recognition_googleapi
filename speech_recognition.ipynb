{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-to-text Transcription using Google API\n",
    "This notebook shows a few options for converting video to audio to text\n",
    "\n",
    "- Convert video -> audio\n",
    "- Convert audio -> text using Google Cloud [speech-to-text API](https://cloud.google.com/speech-to-text/)\n",
    "    - Simple conversion for small files (no GCP account required)\n",
    "    - Queue up larger files up to 480 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert video -> audio\n",
    "\n",
    "First, install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install SpeechRecognition moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "chunk:  26%|██▋       | 307/1159 [00:00<00:00, 3063.62it/s, now=None]MoviePy - Writing audio in fold_in_the_cheese.wav\n",
      "                                                                      MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "# Load video file\n",
    "clip = mp.VideoFileClip(r\"fold_in_the_cheese.mp4\") \n",
    "\n",
    "# Create .wav file\n",
    "clip.audio.write_audiofile(r\"fold_in_the_cheese.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File should be created in directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert audio to text\n",
    "\n",
    "Google Cloud Platform has 3 types of speech recognition platforms. More details on [Google Cloud Platform](https://cloud.google.com/speech-to-text/docs/basics)\n",
    "\n",
    "1. Small audio files - for audio files ~1 minute long\n",
    "2. Larger audio files - use the **Long Running Operation**. up to ~480 minutes\n",
    "3. Real-time conversion - *not* used in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Small audio files - No Google Account\n",
    "\n",
    "You can get a limited amount of transcription *without* a Google account by using this code.\n",
    "\n",
    "The amount of text is really limited. Not covered in this notebook, but you can still get around this limitation with longer files by doing the following:\n",
    "\n",
    "1. Chunk your audio file into small sizes. There are ways to do this by silence so that words are not cut off unexpectedly\n",
    "2. Iterate through this synchronous API call with each audio chunk\n",
    "3. Merge resulting transcriptions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "\n",
    "# Define recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Load audio file\n",
    "audio_filename = \"fold_in_the_cheese.wav\"\n",
    "audio = sr.AudioFile(path + audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Output: it's not your mother's recipe to you to try to keep up next step is to fold in the cheese\n"
     ]
    }
   ],
   "source": [
    "with audio as source:\n",
    "  audio_file = r.record(source)\n",
    "result = r.recognize_google(audio_file)\n",
    "\n",
    "print(f'Output: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write that to a file in directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File fold_in_the_cheese.txt is created\n"
     ]
    }
   ],
   "source": [
    "transcript_filename = audio_filename.split('.')[0] + '.txt'\n",
    "\n",
    "f = open(transcript_filename,\"w\")\n",
    "f.write(result)\n",
    "f.close()\n",
    "\n",
    "print(f'File {transcript_filename} is created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small audio files - with Google account\n",
    "\n",
    "Limit is ~ 1 minute duration. \n",
    "\n",
    "In this next section, we will use a Google account to perform speech recognition.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Speech-to-text API service setup\n",
    "2. Storage setup - required to upload to storage in order to queue audio file for conversion\n",
    "3. Convert audio -> text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Speech-to-text API service Setup\n",
    "\n",
    "It is required to **first** sign up for GCP account and create a speech-to-text service. Follow this Google [guide](https://cloud.google.com/speech-to-text/docs/quickstart-client-libraries) to do that\n",
    "\n",
    "Below are steps part of the install guide to set json path and confirm functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps provided for setting the environment variable ```GOOGLE_APPLICATION_CREDENTIALS``` from the terminal did not work for me, but this code below did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "json_path = {your_path}\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=json_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is provided by Google to test your setup. Output should read:\n",
    "\n",
    "\"Transcript: how old is the Brooklyn Bridge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transcript: how old is the Brooklyn Bridge\n"
     ]
    }
   ],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"\n",
    "\n",
    "audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"en-US\",\n",
    ")\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "for result in response.results:\n",
    "    print(\"Transcript: {}\".format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Google Cloud Storage Setup\n",
    "\n",
    "Follow Google [guide](https://cloud.google.com/storage) to create storage\n",
    "\n",
    "OR \n",
    "\n",
    "Use the following to create new storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bucket my-new-bucket-creek created.\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "from google.cloud import storage\n",
    "\n",
    "# set client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# name bucket\n",
    "bucket_name = \"my-new-bucket-creek\"\n",
    "\n",
    "# create bucket\n",
    "bucket = storage_client.create_bucket(bucket_name)\n",
    "\n",
    "print(\"Bucket {} created.\".format(bucket.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Convert audio -> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transcript: This is not your mother's recipe. Yes, and now I'm passing it on to you. So try to keep up. Oh next step is to fold in the cheese.\nTranscript:  What does that mean? What does fold in the cheese mean? He holds it in I understand that but how do you fold it? Do you fold it in half like a piece of paper and drop it in the pot or what do you do and I cannot show you everything. Okay? Well, can you show me one thing you just what you do? You just fold it in. Okay. I don't know how to fold broken cheese like that. I don't know how to be any clearer. You take that thing that's in your head, huh? And you if you say fooled in one more time.\nTranscript:  I'm that's follows it in. This is your recipe you fooled in the cheese, then don't you dare you fold it in David?\n"
     ]
    }
   ],
   "source": [
    "# The name of the audio file to transcribe\n",
    "bucket = 'my-new-bucket-creek'\n",
    "audio_file = 'fold_in_the_cheese.wav'\n",
    "\n",
    "gcs_uri = 'gs://' + bucket + '/' + audio_file\n",
    "\n",
    "audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    #sample_rate_hertz=44100, #not required for .wav files since the frame rate is in the header\n",
    "    language_code=\"en-US\",\n",
    "    model='video', #specify model if applicable\n",
    "    enable_automatic_punctuation=True)\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config=config, audio=audio) #synchronous\n",
    "\n",
    "for result in response.results:\n",
    "    print(\"Transcript: {}\".format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Larger audio files - up to ~480 minutes\n",
    "\n",
    "Import libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud import storage\n",
    "\n",
    "def prep_audio_file(audio_file):\n",
    "    '''\n",
    "    This function makes sure audio file meets requirements for transcription:\n",
    "    - Must be mono\n",
    "    '''\n",
    "    # modify audio file\n",
    "    sound = AudioSegment.from_wav(audio_file)\n",
    "    sound = sound.set_channels(1)\n",
    "\n",
    "    # can be useful to resample rate to 16000. google recommends to not do this but can be used to tune\n",
    "    # sound = sound.set_frame_rate(16000) \n",
    "    sound.export(audio_file, format=\"wav\")\n",
    "    return\n",
    "\n",
    "def upload_blob(bucket_name, audio_file, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\n",
    "    Inputs: \n",
    "        # bucket_name = \"your bucket name\"\n",
    "        # audio_path = \"path to file\"\n",
    "        # audio_file = \"file name\"\n",
    "        # destination_blob_name = \"storage object name\"\n",
    "    \"\"\"\n",
    "\n",
    "    # upload audio file to storage bucket    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.chunk_size = 5 * 1024 * 1024 # Set 5 MB blob size\n",
    "    blob.upload_from_filename(audio_file)\n",
    "\n",
    "    print('File upload complete')\n",
    "    return\n",
    "\n",
    "def write_transcripts(transcript_file, transcript):\n",
    "    f = open(transcript_file,\"w\")\n",
    "    f.write(transcript)\n",
    "    f.close()\n",
    "    return\n",
    "\n",
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\n",
    "    Inputs:\n",
    "        # bucket_name = \"your bucket name\"\n",
    "        # blob_name = \"storage object name\"\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.delete()\n",
    "\n",
    "    print(f'Blob {blob_name} deleted')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple transcription - single blob of text without speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_transcribe_single(audio_file, bucket): \n",
    "    # convert audio to text\n",
    "    gcs_uri = 'gs://' + bucket + '/' + audio_file\n",
    "    transcript = ''\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    frame_rate = 44100 \n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        language_code='en-US',\n",
    "        model='video', # optional: specify audio source. This increased transcription accuracy when turned on\n",
    "        enable_automatic_punctuation=True) # optional: Enable automatic punctuation\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config=config, audio=audio) #asynchronous\n",
    "    response = operation.result(timeout=10000)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript += result.alternatives[0].transcript\n",
    "    \n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File upload complete\n",
      "Transcript fold_in_the_cheese.txt created\n"
     ]
    }
   ],
   "source": [
    "bucket = 'my-new-bucket-creek'\n",
    "audio_file = 'fold_in_the_cheese.wav'\n",
    "\n",
    "# do only if file is .wav\n",
    "prep_audio_file(audio_file)\n",
    "\n",
    "# # upload audio file to storage bucket    \n",
    "upload_blob(bucket, audio_file, audio_file)\n",
    "\n",
    "# create transcript\n",
    "transcript = google_transcribe_single(audio_file, bucket)\n",
    "transcript_file = audio_file.split('.')[0] + '.txt'\n",
    "\n",
    "write_transcripts(transcript_file, transcript)\n",
    "print(f'Transcript {transcript_file} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove audio file from bucket\n",
    "delete_blob(bucket, audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple speaker transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech_beta\n",
    "from google.cloud.speech_v1p1beta1 import types as types_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_transcribe_speakers(audio_file, bucket):\n",
    "    \n",
    "    gcs_uri = 'gs://' + bucket + '/' + audio_file\n",
    "    transcript = ''\n",
    "    \n",
    "    client = speech_beta.SpeechClient()\n",
    "    audio = speech_beta.RecognitionAudio(uri=gcs_uri)\n",
    "    frame_rate = 44100 #set your frame rate\n",
    "\n",
    "    config = types_beta.RecognitionConfig(\n",
    "        encoding=speech_beta.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        language_code='en-US',\n",
    "        enable_automatic_punctuation=True, # Enable automatic punctuation\n",
    "        model='video',\n",
    "        enable_speaker_diarization=True,\n",
    "        diarization_speaker_count=2)\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    response = operation.result(timeout=10000)\n",
    "\n",
    "    # The transcript within each result is separate and sequential per result.\n",
    "    # However, the words list within an alternative includes all the words\n",
    "    # from all the results thus far. Thus, to get all the words with speaker\n",
    "    # tags, you only have to take the words list from the last result:\n",
    "    result = response.results[-1] \n",
    "    words_info = result.alternatives[0].words \n",
    "    \n",
    "    tag=1 \n",
    "    speak=\"\" \n",
    "\n",
    "    for word_info in words_info:\n",
    "        if word_info.speaker_tag==tag:\n",
    "            speak = speak + \" \" + word_info.word\n",
    "        else:\n",
    "            transcript += f'speaker {tag}: {speak}' + '\\n'\n",
    "            tag = word_info.speaker_tag \n",
    "            speak = word_info.word\n",
    " \n",
    "    transcript += f'speaker {tag}: {speak}'\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File upload complete\n",
      "Transcript fold_in_the_cheese_speakers.txt created\n"
     ]
    }
   ],
   "source": [
    "bucket = 'my-new-bucket-creek'\n",
    "audio_file = 'fold_in_the_cheese.wav'\n",
    "\n",
    "# do only if file is .wav\n",
    "prep_audio_file(audio_file)\n",
    "\n",
    "# upload audio file to storage bucket    \n",
    "upload_blob(bucket, audio_file, audio_file)\n",
    "\n",
    "transcript = google_transcribe_speakers(audio_file, bucket)\n",
    "transcript_file = audio_file.split('.')[0] + '_speakers' + '.txt'\n",
    "\n",
    "write_transcripts(transcript_file, transcript)\n",
    "print(f'Transcript {transcript_file} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove audio file from bucket\n",
    "delete_blob(bucket, audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling word timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_word_time_offsets(audio_file, bucket):\n",
    "    \"\"\"Transcribe the given audio file asynchronously and output the word time\n",
    "    offsets.\"\"\"\n",
    "    gcs_uri = 'gs://' + bucket + '/' + audio_file\n",
    "    transcript = ''\n",
    "\n",
    "    client = speech_beta.SpeechClient()\n",
    "    audio = speech_beta.RecognitionAudio(uri=gcs_uri)\n",
    "    frame_rate = 44100\n",
    "\n",
    "    config = types_beta.RecognitionConfig(\n",
    "        encoding=speech_beta.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        language_code='en-US',\n",
    "        enable_automatic_punctuation=True, # Enable automatic punctuation\n",
    "        enable_word_time_offsets=True)\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print('Waiting for operation to complete...')\n",
    "    result = operation.result(timeout=10000)\n",
    "\n",
    "    for result in result.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        print('Transcript: {}'.format(alternative.transcript))\n",
    "        print('Confidence: {}'.format(alternative.confidence))\n",
    "\n",
    "        for word_info in alternative.words:\n",
    "            word = word_info.word\n",
    "            start_time = word_info.start_time\n",
    "            end_time = word_info.end_time\n",
    "            print('Word: {}, start_time: {}, end_time: {}'.format(\n",
    "                word,\n",
    "                start_time.total_seconds(),\n",
    "                end_time.total_seconds()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File upload complete\n",
      "Waiting for operation to complete...\n",
      "Transcript: It's not your mother's recipe said now, I'm passing it on to you. So try to keep up next step is to fold in the cheese.\n",
      "Confidence: 0.9347954988479614\n",
      "Word: It's, start_time: 0.0, end_time: 0.2\n",
      "Word: not, start_time: 0.2, end_time: 0.4\n",
      "Word: your, start_time: 0.4, end_time: 0.5\n",
      "Word: mother's, start_time: 0.5, end_time: 0.8\n",
      "Word: recipe, start_time: 0.8, end_time: 1.2\n",
      "Word: said, start_time: 1.2, end_time: 1.7\n",
      "Word: now,, start_time: 1.7, end_time: 1.8\n",
      "Word: I'm, start_time: 1.8, end_time: 2.0\n",
      "Word: passing, start_time: 2.0, end_time: 2.3\n",
      "Word: it, start_time: 2.3, end_time: 2.4\n",
      "Word: on, start_time: 2.4, end_time: 2.5\n",
      "Word: to, start_time: 2.5, end_time: 2.7\n",
      "Word: you., start_time: 2.7, end_time: 3.0\n",
      "Word: So, start_time: 3.0, end_time: 3.5\n",
      "Word: try, start_time: 3.5, end_time: 3.8\n",
      "Word: to, start_time: 3.8, end_time: 3.9\n",
      "Word: keep, start_time: 3.9, end_time: 4.1\n",
      "Word: up, start_time: 4.1, end_time: 4.4\n",
      "Word: next, start_time: 4.4, end_time: 6.7\n",
      "Word: step, start_time: 6.7, end_time: 7.0\n",
      "Word: is, start_time: 7.0, end_time: 7.1\n",
      "Word: to, start_time: 7.1, end_time: 7.2\n",
      "Word: fold, start_time: 7.2, end_time: 7.6\n",
      "Word: in, start_time: 7.6, end_time: 7.9\n",
      "Word: the, start_time: 7.9, end_time: 8.0\n",
      "Word: cheese., start_time: 8.0, end_time: 8.2\n",
      "Transcript:  What is that mean? What does fold in the cheese mean? I understand that but how how do you fold it to fold it in half like a piece of paper and drop it in the pot or what do you do and I cannot show you everything. Okay? What can you show me one thing?\n",
      "Confidence: 0.9210773706436157\n",
      "Word: What, start_time: 11.6, end_time: 11.9\n",
      "Word: is, start_time: 11.9, end_time: 12.0\n",
      "Word: that, start_time: 12.0, end_time: 12.1\n",
      "Word: mean?, start_time: 12.1, end_time: 12.3\n",
      "Word: What, start_time: 12.3, end_time: 13.0\n",
      "Word: does, start_time: 13.0, end_time: 13.1\n",
      "Word: fold, start_time: 13.1, end_time: 13.3\n",
      "Word: in, start_time: 13.3, end_time: 13.4\n",
      "Word: the, start_time: 13.4, end_time: 13.5\n",
      "Word: cheese, start_time: 13.5, end_time: 13.6\n",
      "Word: mean?, start_time: 13.6, end_time: 14.0\n",
      "Word: I, start_time: 14.0, end_time: 16.8\n",
      "Word: understand, start_time: 16.8, end_time: 17.5\n",
      "Word: that, start_time: 17.5, end_time: 17.6\n",
      "Word: but, start_time: 17.6, end_time: 17.8\n",
      "Word: how, start_time: 17.8, end_time: 18.0\n",
      "Word: how, start_time: 18.0, end_time: 18.1\n",
      "Word: do, start_time: 18.1, end_time: 18.5\n",
      "Word: you, start_time: 18.5, end_time: 18.5\n",
      "Word: fold, start_time: 18.5, end_time: 18.8\n",
      "Word: it, start_time: 18.8, end_time: 19.0\n",
      "Word: to, start_time: 19.0, end_time: 19.2\n",
      "Word: fold, start_time: 19.2, end_time: 19.5\n",
      "Word: it, start_time: 19.5, end_time: 19.6\n",
      "Word: in, start_time: 19.6, end_time: 19.8\n",
      "Word: half, start_time: 19.8, end_time: 19.8\n",
      "Word: like, start_time: 19.8, end_time: 20.2\n",
      "Word: a, start_time: 20.2, end_time: 20.3\n",
      "Word: piece, start_time: 20.3, end_time: 20.5\n",
      "Word: of, start_time: 20.5, end_time: 20.5\n",
      "Word: paper, start_time: 20.5, end_time: 20.7\n",
      "Word: and, start_time: 20.7, end_time: 20.9\n",
      "Word: drop, start_time: 20.9, end_time: 21.1\n",
      "Word: it, start_time: 21.1, end_time: 21.2\n",
      "Word: in, start_time: 21.2, end_time: 21.3\n",
      "Word: the, start_time: 21.3, end_time: 21.4\n",
      "Word: pot, start_time: 21.4, end_time: 21.7\n",
      "Word: or, start_time: 21.7, end_time: 21.8\n",
      "Word: what, start_time: 21.8, end_time: 22.0\n",
      "Word: do, start_time: 22.0, end_time: 22.0\n",
      "Word: you, start_time: 22.0, end_time: 22.1\n",
      "Word: do, start_time: 22.1, end_time: 22.3\n",
      "Word: and, start_time: 22.3, end_time: 23.2\n",
      "Word: I, start_time: 23.2, end_time: 23.4\n",
      "Word: cannot, start_time: 23.4, end_time: 23.9\n",
      "Word: show, start_time: 23.9, end_time: 24.1\n",
      "Word: you, start_time: 24.1, end_time: 24.2\n",
      "Word: everything., start_time: 24.2, end_time: 24.6\n",
      "Word: Okay?, start_time: 24.6, end_time: 24.9\n",
      "Word: What, start_time: 24.9, end_time: 25.2\n",
      "Word: can, start_time: 25.2, end_time: 25.4\n",
      "Word: you, start_time: 25.4, end_time: 25.5\n",
      "Word: show, start_time: 25.5, end_time: 25.7\n",
      "Word: me, start_time: 25.7, end_time: 25.7\n",
      "Word: one, start_time: 25.7, end_time: 26.1\n",
      "Word: thing?, start_time: 26.1, end_time: 26.3\n",
      "Transcript:  You just have to do it in like that.\n",
      "Confidence: 0.7932881116867065\n",
      "Word: You, start_time: 28.3, end_time: 28.7\n",
      "Word: just, start_time: 28.7, end_time: 29.1\n",
      "Word: have, start_time: 29.1, end_time: 29.6\n",
      "Word: to, start_time: 29.6, end_time: 29.6\n",
      "Word: do, start_time: 29.6, end_time: 30.1\n",
      "Word: it, start_time: 30.1, end_time: 30.5\n",
      "Word: in, start_time: 30.5, end_time: 31.4\n",
      "Word: like, start_time: 31.4, end_time: 34.1\n",
      "Word: that., start_time: 34.1, end_time: 34.4\n",
      "Transcript:  You take that thing between your house and you if you say fooled in one more time, this is your recipe you fold in the cheese, then don't you know full did it?\n",
      "Confidence: 0.8899783492088318\n",
      "Word: You, start_time: 35.7, end_time: 36.5\n",
      "Word: take, start_time: 36.5, end_time: 36.8\n",
      "Word: that, start_time: 36.8, end_time: 37.0\n",
      "Word: thing, start_time: 37.0, end_time: 37.2\n",
      "Word: between, start_time: 37.2, end_time: 37.4\n",
      "Word: your, start_time: 37.4, end_time: 37.7\n",
      "Word: house, start_time: 37.7, end_time: 38.1\n",
      "Word: and, start_time: 38.1, end_time: 38.2\n",
      "Word: you, start_time: 38.2, end_time: 38.9\n",
      "Word: if, start_time: 38.9, end_time: 39.1\n",
      "Word: you, start_time: 39.1, end_time: 39.2\n",
      "Word: say, start_time: 39.2, end_time: 39.5\n",
      "Word: fooled, start_time: 39.5, end_time: 39.9\n",
      "Word: in, start_time: 39.9, end_time: 40.1\n",
      "Word: one, start_time: 40.1, end_time: 40.9\n",
      "Word: more, start_time: 40.9, end_time: 41.1\n",
      "Word: time,, start_time: 41.1, end_time: 41.2\n",
      "Word: this, start_time: 41.2, end_time: 43.9\n",
      "Word: is, start_time: 43.9, end_time: 44.2\n",
      "Word: your, start_time: 44.2, end_time: 44.5\n",
      "Word: recipe, start_time: 44.5, end_time: 45.0\n",
      "Word: you, start_time: 45.0, end_time: 45.6\n",
      "Word: fold, start_time: 45.6, end_time: 46.0\n",
      "Word: in, start_time: 46.0, end_time: 46.1\n",
      "Word: the, start_time: 46.1, end_time: 46.2\n",
      "Word: cheese,, start_time: 46.2, end_time: 46.3\n",
      "Word: then, start_time: 46.3, end_time: 46.9\n",
      "Word: don't, start_time: 46.9, end_time: 47.3\n",
      "Word: you, start_time: 47.3, end_time: 47.5\n",
      "Word: know, start_time: 47.5, end_time: 47.8\n",
      "Word: full, start_time: 47.8, end_time: 48.4\n",
      "Word: did, start_time: 48.4, end_time: 48.6\n",
      "Word: it?, start_time: 48.6, end_time: 48.7\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3e2d85b77403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtranscript_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_words'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mwrite_transcripts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Transcript {transcript_file} created'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-5dacc9ce15bd>\u001b[0m in \u001b[0;36mwrite_transcripts\u001b[0;34m(transcript_file, transcript)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_transcripts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "bucket = 'my-new-bucket-creek'\n",
    "audio_file = 'fold_in_the_cheese.wav'\n",
    "\n",
    "# do only if file is .wav\n",
    "prep_audio_file(audio_file)\n",
    "\n",
    "# upload audio file to storage bucket    \n",
    "upload_blob(bucket, audio_file, audio_file)\n",
    "\n",
    "transcribe_word_time_offsets(audio_file, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}